{
  "TASK_SPEECH_RECOGNITION": {
    "input": {
      "type": "object",
      "required": [
        "audio",
        "model"
      ],
      "properties": {
        "audio": {
          "description": "The audio file object (not file name) to transcribe, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm.\n",
          "type": "string",
          "x-oaiTypeLabel": "file",
          "format": "binary",
          "title": "Audio",
          "instillFormat": "audio",
          "instillUpstreamTypes": [
            "reference"
          ]
        },
        "model": {
          "description": "ID of the model to use. Only `whisper-1` is currently available.\n",
          "example": "whisper-1",
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "string",
              "enum": [
                "whisper-1"
              ]
            }
          ],
          "x-oaiTypeLabel": "string",
          "title": "Model",
          "instillFormat": "text",
          "instillUpstreamTypes": [
            "value",
            "reference"
          ]
        },
        "temperature": {
          "description": "The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.\n",
          "type": "number",
          "default": 0,
          "title": "Temperature",
          "instillFormat": "number",
          "instillUpstreamTypes": [
            "value",
            "reference"
          ]
        },
        "language": {
          "description": "The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.\n",
          "type": "string",
          "title": "Language",
          "instillFormat": "text",
          "instillUpstreamTypes": [
            "value",
            "reference"
          ]
        },
        "prompt": {
          "description": "An optional text to guide the model's style or continue a previous audio segment. The [prompt](https://platform.openai.com/docs/guides/speech-to-text/prompting) should match the audio language.\n",
          "type": "string",
          "title": "Prompt",
          "instillFormat": "text",
          "instillUpstreamTypes": [
            "value",
            "reference"
          ]
        }
      }
    },
    "output": {
      "type": "object",
      "properties": {
        "text": {
          "type": "string",
          "instillFormat": "text"
        }
      }
    }
  },
  "TASK_TEXT_EMBEDDINGS": {
    "input": {
      "type": "object",
      "required": [
        "text",
        "model"
      ],
      "properties": {
        "text": {
          "title": "Text",
          "type": "string",
          "instillFormat": "text",
          "instillUpstreamTypes": [
            "value",
            "reference"
          ]
        },
        "model": {
          "description": "ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models/overview) for descriptions of them.\n",
          "example": "text-embedding-ada-002",
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "string",
              "enum": [
                "text-embedding-ada-002"
              ]
            }
          ],
          "x-oaiTypeLabel": "string",
          "title": "Model",
          "instillFormat": "text",
          "instillUpstreamTypes": [
            "value",
            "reference"
          ]
        }
      }
    },
    "output": {
      "type": "object",
      "properties": {
        "embedding": {
          "type": "array",
          "instillFormat": "number_array",
          "items": {
            "type": "number",
            "instillFormat": "number"
          }
        }
      }
    }
  },
  "TASK_TEXT_GENERATION": {
    "input": {
      "type": "object",
      "required": [
        "model",
        "prompt"
      ],
      "properties": {
        "prompt": {
          "title": "Prompt",
          "type": "string",
          "instillFormat": "text",
          "instillUpstreamTypes": [
            "value",
            "reference"
          ]
        },
        "model": {
          "description": "ID of the model to use. See the [model endpoint compatibility](https://platform.openai.com/docs/models/model-endpoint-compatibility) table for details on which models work with the Chat API.",
          "example": "gpt-3.5-turbo",
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "string",
              "enum": [
                "gpt-4",
                "gpt-4-0314",
                "gpt-4-0613",
                "gpt-4-32k",
                "gpt-4-32k-0314",
                "gpt-4-32k-0613",
                "gpt-3.5-turbo",
                "gpt-3.5-turbo-16k",
                "gpt-3.5-turbo-0301",
                "gpt-3.5-turbo-0613",
                "gpt-3.5-turbo-16k-0613"
              ]
            }
          ],
          "x-oaiTypeLabel": "string",
          "title": "Model",
          "instillFormat": "text",
          "instillUpstreamTypes": [
            "value",
            "reference"
          ]
        },
        "system_message": {
          "title": "System message",
          "description": "The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. By default, the model\u2019s behavior is using a generic message as \"You are a helpful assistant.\"",
          "type": "string",
          "default": "You are a helpful assistant.",
          "maxLength": 2048,
          "instillFormat": "text",
          "instillUpstreamTypes": [
            "value",
            "reference"
          ]
        },
        "temperature": {
          "type": "number",
          "minimum": 0,
          "maximum": 2,
          "default": 1,
          "example": 1,
          "nullable": true,
          "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\nWe generally recommend altering this or `top_p` but not both.\n",
          "title": "Temperature",
          "instillFormat": "number",
          "instillUpstreamTypes": [
            "value",
            "reference"
          ]
        },
        "n": {
          "type": "integer",
          "minimum": 1,
          "maximum": 128,
          "default": 1,
          "example": 1,
          "nullable": true,
          "description": "How many chat completion choices to generate for each input message.",
          "title": "N",
          "instillFormat": "integer",
          "instillUpstreamTypes": [
            "value",
            "reference"
          ]
        },
        "max_tokens": {
          "description": "The maximum number of [tokens](/tokenizer) to generate in the chat completion.\n\nThe total length of input tokens and generated tokens is limited by the model's context length. [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb) for counting tokens.\n",
          "default": "inf",
          "type": "integer",
          "title": "Max Tokens",
          "instillFormat": "integer",
          "instillUpstreamTypes": [
            "value",
            "reference"
          ]
        }
      }
    },
    "output": {
      "type": "object",
      "properties": {
        "texts": {
          "type": "array",
          "items": {
            "type": "string",
            "instillFormat": "text"
          },
          "instillFormat": "text_array"
        }
      }
    }
  }
}
